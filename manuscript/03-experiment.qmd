# Experiment setup {#sec-experiment}


## Data {#sec-data}

For this study, we use a dataset spanning five years (Dec. 2017- July 2022) of consumption data obtained from EPSS. Rigorous checks were conducted to ensure the consistency and completeness of the collected data. From the extensive pool of pharmaceutical products within EPSS, we selected a set of 33 key pharmaceuticals, including various programs and representing different classes of drugs. 

### Explaoratory Data Analysis with consumption data

Given the number of products in this study, we created several data plot and computed features of the time series, including the strength of trend and seasonality to better understadn data. @fig-feature shows the strength of trend versus seasonality. Each point represents one time series with the strength of trend in x-axis and the strength of seasonality in y-axis. Both measures are on a scale of [0,1]. the strength of trend and seasonality were calculated using the "STL" (Seasonal and Trend decomposition using Loess) decomposition method, as described by @bandara2025mstl


```{r}
#| label: fig-feature
#| cache: true
#| out.width: "60%"
#| fig.align: center
#| fig-cap: "The strength of the trend and seasonality in the time series of pharmaceutical product consumption. The scatter plot shows 33 data points, with each point corresponding to a product."

med_qty <- read_csv("../data/predicotrs_final_tssible_July_04_2024.csv") |> 
  janitor::clean_names() |> mutate(month = yearmonth(month))

med_qty_tsb <- med_qty |> 
  as_tsibble(index = month, key = item)

med_qty_tsb %>%
  features(quantity, feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_year)) +
  geom_point(alpha = 0.25) +
  labs(x = "Strength of trend", y = "Strength of seasonality")+
  ggthemes::theme_few()
```


It is evident that some time series display strong trends and/or seasonality, while the majority exhibit low trends and minimal seasonality. A number of products show pronounced trends, and only a few demonstrate clear seasonal patterns. Beyond assessing the strength of trends and seasonality, we also visualized all time series to understand data and various patterns, including trends and instances of erratic consumption behavior during certain months. For example, some series show low consumption volumes over consecutive months, followed by peak consumption in specific months, making them more volatile and difficult to forecast. This underscores the diversity of monthly pharmaceutical time series patterns within the dataset and highlights the importance of understanding the factors driving these consumption behaviors. Figure @fig-dataviz2 illustrates the time plots for a few selected products.

```{r}
#| label: fig-dataviz2
#| cache: true
#| dependson: "fig-feature"
#| fig-width: 11
#| fig-height: 6
#| fig-cap: "Monthly time plot of consumption. X-axis shows the month, consisting of 60 data points (months) and y-axis shows the comsumption. The panels display data from four products to give a glimpse of the consumption patterns."

p1 <- ggplot(med_qty |> filter(item == "Oxytocin") |> select(-item), 
       aes(x=month, y=quantity))+
  geom_point()+
  geom_line(aes(group =1))+
  scale_x_yearmonth(date_breaks = "4 month")+
  labs(x = "Month", y = "Consumption", title = "Oxytocin")+
  ggthemes::theme_few()+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

p2 <- ggplot(med_qty |> filter(item == "Amoxicillin - 500mg - Capsule") |> select(-item), 
       aes(x=month, y=quantity))+
  geom_point()+
  geom_line(aes(group =1))+
  scale_x_yearmonth(date_breaks = "4 month")+
    labs(x = "Month", y = "Consumption",title = "Amoxicillin - 500mg - Capsule")+
  ggthemes::theme_few()+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

p3 <- ggplot(med_qty |> filter(item == "Ceftriaxone") |> select(-item), 
       aes(x=month, y=quantity))+
  geom_point()+
  geom_line(aes(group =1))+
  scale_x_yearmonth(date_breaks = "4 month")+
    labs(x = "Month", y = "Consumption",title = "Ceftriaxone")+
  ggthemes::theme_few()+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

p4 <- ggplot(med_qty |> filter(item == "Atenolol - 50mg - Tablet") |> select(-item), 
       aes(x=month, y=quantity))+
  geom_point()+
  geom_line(aes(group =1))+
  scale_x_yearmonth(date_breaks = "4 month")+
    labs(x = "Month", y = "Consumption", title = "Atenolol - 50mg - Tablet")+
  ggthemes::theme_few()+
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

patch <- (p1 | p2) /
(p3 | p4) 
patch+ggthemes::theme_few()
```

Visualizing the data revealed that various events significantly impacted the consumption of different products, but these were not reflected in the available data. Expert insights were crucial for understanding the nature and timing of these events, filling gaps in the system, and incorporating qualitative factors that EPSS logistics system miss. Therefore, we conducted interviews with domain experts to collect information on external factors that influence consumption. These interviews allowed us to account for unusual patterns and customize our forecasting models to more accurately reflect the unique consumption behaviors of each product.



```{r}
#| label: tbl-feature
#| echo: false
#| cache: false
#| tbl-cap: "Summary statistics of the pharmaceutical product time series"
#| tbl-pos: "H"

library(fpp3)
all_feature <- med_qty_tsb %>%
  features(quantity, feature_set(pkgs = "feasts")) |> dplyr::select(`ACF lag 1`=acf1,zero_run_mean,nonzero_squared_cv)

summary_stat <- med_qty_tsb %>%
  features(quantity,list(Mean = mean, Median=median, `Standard deviation`=sd, Miinum=min, Maximum=max)) |> 
  bind_cols(all_feature) |> mutate(across(where(is.numeric), ~ round(.x, 2)))
summary_stat |> 
  knitr::kable(booktabs = T, linesep = "") |>
  kable_styling(latex_options = c("scale_down"))
```


@tbl-feature also provides the summary statistics computed for each pharmaceutical product time series include traditional distributional measures—mean, median, standard deviation, minimum, and maximum—alongside time series–specific and structural characteristics. These include the first-order autocorrelation (ACF at lag 1), the mean length of consecutive zero runs (zero_run_mean), and the squared coefficient of variation computed only on non-zero values (nonzero_squared_cv). Together, these metrics capture not only central tendency and dispersion, but also temporal dependence, sparsity patterns, and relative variability in periods with non-zero consumption.


## Collaborative expert review to identify factors affecting consumption

\textcolor{blue}{To incorporate expert knowledge into time series forecasting in a structured and replicable manner, we developed a multi-step process involving expert engagement, collaborative data review, and operational validation. In partnership with the Forecasting and Market Shaping Directorate at EPSS, we identified six experienced professionals from the Warehouse and Inventory Management Directorate with deep operational knowledge of pharmaceutical logistics.}


Figure \ref{fig:expert-pipeline} \textcolor{blue}{presents a visual overview of the end-to-end approach, highlighting each major stage of the process from expert engagement to model integration.}


```{=latex}
\begin{figure}[htbp]
\centering
\begin{tikzpicture}[scale=0.85, transform shape, node distance=1.3cm and 2cm]

% Node style
\tikzset{
  process/.style={
    rectangle,
    draw=black,
    thick,
    text width=4.5cm,
    align=center,
    minimum height=1.4cm
  },
  arrow/.style={
    thick,
    ->,
    >=Stealth
  }
}

% Nodes
\node (step1) [process] {1. Expert Identification (with EPSS)};
\node (step2) [process, below=of step1] {2. Onboarding \& Orientation};
\node (step3) [process, below=of step2] {3. Workshop: Collaborative Data Review \& Joint Identification of Anomalies};

\node (step4) [process, right=of step1] {4. Cross Validation Using Bin Cards \& Inventory Records};
\node (step5) [process, below=of step4] {5. Structured Expert Elicitation \& Contextual Clarification};

\node (step6) [process, right=of step4] {6. Expert Elicitation of Predictor Relevance};
\node (step7) [process, below=of step6] {7. Consensus-Based Selection of Predictors};
\node (step8) [process, below=of step7] {8. Variable Encoding \& Time Alignment};

\node (step9) [process, below=of step8, yshift=-0.3cm] {9. Integration into Forecasting Models};

% Arrows
\draw [arrow] (step1) -- (step2);
\draw [arrow] (step2) -- (step3);

\path (step3.east) -- +(0.6,0) coordinate (s3stub);
\draw [arrow] (step3.east) -- (s3stub) |- (step4.west);

\draw [arrow] (step4) -- (step5);

\path (step5.east) -- +(0.6,0) coordinate (s5stub);
\draw [arrow] (step5.east) -- (s5stub) |- (step6.west);

\draw [arrow] (step6) -- (step7);
\draw [arrow] (step7) -- (step8);
\draw [arrow] (step8) -- (step9);

% Group boxes
\node[draw=black, thick, dashed, inner sep=0.3cm, rounded corners, fit=(step1)(step2)(step3), label={[black]90:Expert Engagement}] {};
\node[draw=black, thick, dashed, inner sep=0.3cm, rounded corners, fit=(step4)(step5), label={[black]90:Validation}] {};
\node[draw=black, thick, dashed, inner sep=0.3cm, rounded corners, fit=(step6)(step7)(step8), label={[black]90:Feature Construction}] {};
\node[draw=black, thick, dashed, inner sep=0.3cm, rounded corners, fit=(step9), label={[black]90:Model Integration}] {};

\end{tikzpicture}
\caption{Diagram illustrating the sequential steps involved in collecting, structuring, and utilizing domain knowledge for modeling.}
\label{fig:expert-pipeline}
\end{figure}

```



\textcolor{blue}{Through a facilitated half-day workshop, these experts reviewed five years of monthly consumption data for 33 pharmaceutical products. Anomalous patterns—such as consumption spikes, prolonged lows, and erratic fluctuations—were jointly identified and interpreted in light of operational events (e.g., emergency distributions, inventory cycles). These insights were cross-validated against bin cards and warehouse records, and internal transfers were excluded to isolate externally relevant events. Dates were standardized to the Gregorian calendar.}

\textcolor{blue}{Predictor variables were defined through expert consensus, with inclusion contingent on agreement among all six core participants regarding the operational relevance and causal validity of each factor. The final predictors included binary indicators for stock replenishment events, categorical variables for fiscal year inventory counts, and dummy variables for malaria seasonality. A further description of these variables are summarized as followings:}

- \textcolor{blue}{Stock replenishment:  refers to the process of restocking or refilling inventory to ensure that there are sufficient quantities of products or materials available to meet demand. Whenever there was stock replenishment at the central EPSS, consumption and distribution to hubs and health facilities increased. This increase was attributed to the need to restock depleted inventories and the push from central EPSS to manage space constraints.}

- \textcolor{blue}{Physical fiscal year inventory counting: refers to the process of manually counting and verifying the actual quantities of pharmaceutical products available in stock at a specific location. The process is critical for maintaining the accuracy of inventory records, ensuring that medicines are available when needed, and preventing stockouts or overstocking.  Physical inventory counting periods also influenced consumption. Stores closed during these periods, halting transactions. We observed increased consumption before inventory counting periods, as hubs and facilities stocked up. July and August were identified as physical counting periods each year.}

- \textcolor{blue}{Malaria seasonality: Refers to the predictable patterns and fluctuations in malaria incidence throughout the year, typically influenced by climate and environmental conditions. In many regions, malaria transmission peaks during and shortly after the rainy season, when conditions such as stagnant water pools create ideal breeding sites for the Anopheles mosquitoes that transmit the disease. Conversely, malaria cases often decline during the dry season when mosquito breeding sites are reduced. During peak malaria seasons, there is a significant surge in the demand for antimalarial drugs and other related treatments. Malaria seasonality was another significant predictor. Certain pharmaceuticals, like Artemether + Lumefanthrine and Rapid Diagnostic Test kits, were affected by malaria outbreaks. We identified epidemic periods affecting consumption: September to December 2017, March to May 2018, September to December 2018, March to May 2019, September to December 2019, March to May 2020, September to December 2020, March to May 2021, September to December 2021, and March to May 2022.}

\textcolor{blue}{These predictors, encoded with known historical and future values, were added to the modeling dataset. This approach ensured consistent integration of expert-informed contextual variables across both point and probabilistic forecasting models.}

## Forecasting models

We evaluate a range of univariate models and their counterparts that include predictors, spanning from simpler methods like regression, exponential smoothing, and ARIMA to more complex models such as long short-term memory (LSTM) networks and advanced foundational time series forecasting models. Below, we provide a brief overview of these approaches. Detailed implementation codes in R and Python are available in a GitHub repository and accessible for public.


**Exponential Smoothing State Space model (ETS):** ETS models, as described by @hyndman2021forecasting, combine trend, seasonality, and error components in time series using different configurations that can be additive, multiplicative, or mixed. The trend component can be specified as none ("N"), additive ("A"), or damped additive ("Ad"); the seasonality can be none ("N"), additive ("A"), or multiplicative ("M"); and the error term can be additive ("A") or multiplicative ("M"). To forecast consumption, we use the ETS() function from the fable package in R, which automatically selects the optimal model for each time series based on the corrected Akaike’s Information Criterion (AICc). In our study, an automated algorithm determines the best configuration for trend, seasonality, and error components across each time series, leveraging the ets() function’s use of AIC to identify the optimal model. Given the high volume of time series (1530), manual selection of components is impractical, so the algorithm customizes model forms for each series based on its unique characteristics. This results in a tailored combination of additive or multiplicative components, adapting to the specific patterns of each time series.

**Multiple Linear Regression (MLR)**: We use Multiple linear regression to model the relationship between a consumption and potential variables influencing its variation. In our first model, we use multiple linear regression with a trend component to capture the underlying progression over time, i.e., _regression_. We also incorporate dummy variables for each month to account for seasonal fluctuations, without including any additional predictors, i.e., _regression_reg_. This approach helps us establish a baseline model focused solely on temporal trends and seasonal patterns. We then extend this model by introducing additional predictors that include variables such as replenishment cycles, fiscal year indicators, and periods with malaria prevalence. These additional predictors allow the model to see if capturing external factors can provide a better understanding of the factors influencing the consumption and result at enhanced accuracy. We produce forecasts using TLSM() function from the fable package in R.

**ARIMA and ARIMA with regressors**: ARIMA (AutoRegressive Integrated Moving Average) is a powerful statistical model designed to forecast time series by capturing temporal dynamics and are widely used in time series forecasting due to their ability to model complex trends and patterns over time without relying on external predictors. ARIMAX (AutoRegressive Integrated Moving Average with eXogenous variables) extends ARIMA by incorporating external variables, or exogenous predictors, into the model. This modification allows to include relevant information from external factors such as malaria season, and fiscal year period, and stock replenishement period that may explain variations in the series beyond its internal time dynamics, we refer to this in the result as _arima_reg_. By adding these predictors, ARIMAX combines the strengths of ARIMA’s time-series structure with the flexibility of regression models. In our study, we use an automated algorithm to determine the optimal configuration for ARIMA components, following the approach outlined by @hyndman2021forecasting and We use the ARIMA() function from the fable package in R.

**Long Short-Term Memory neural network (LSTM)**: The LSTM model is a specialised form of recurrent neural network (RNN) used to model sequential data by capturing long-term dependencies [@graves2012long]. Unlike traditional RNNs, LSTMs can learn to retain information for longer time periods due to their unique architecture, which consists of several gates that control the flow of information. This makes LSTMs particularly effective for time series forecasting. In our implementation, we used a sequential model architecture, comprising one LSTM layer with 50 units, followed by dense layers, with the final output being a single linear unit. The Adam optimizer was employed to minimize the mean squared error, and the model was trained for 100 epochs using the keras_model_sequential() function from the Keras package in R. We use LSTM models both with and without predictors, referring to the LSTM model with predictors as _lstm_reg_.

\textcolor{blue}{To improve the robustness of the LSTM models and address overfitting issues, we introduced dropout regularization layers after the LSTM units and employed early stopping based on validation loss during model training. Each LSTM model was trained independently for each product series. Hyperparameter tuning was performed in a preliminary phase using a subset of products. Various configurations of LSTM units (30–100), dense units (50–200), dropout rates (0.1–0.5), and batch sizes (16–64) were evaluated based on validation set performance. The final model structure — 50 LSTM units, 100 dense units, a 0.2 dropout rate, and a batch size of 32 — was selected as a trade-off between forecast accuracy and model stability across different demand patterns.}

**TimeGPT**: TimeGPT is the first pre-trained foundational model designed specifically for time series forecasting, developed by Nixtla [@garza2023timegpt]. It uses a transformer-based architecture with an encoder-decoder configuration but differs from other models in that it is not based on large language models. Instead, it is built from the ground up to handle time series data. TimeGPT was trained on more than 100 billion data points, drawing from publicly available time series across various sectors, such as retail, healthcare, transportation, demographics, energy, banking, and web traffic. This wide range of data sources, each with unique temporal patterns, enables the model to manage diverse time series characteristics effectively. Furthermore, TimeGPT supports the inclusion of external regressors in its forecasts and can generate quantile forecasts, providing reliable uncertainty estimation. We use TimeGpt models both with and without predictors, referring to the model with predictors as _timegpt_reg_.

## Generating probabilistic forecasts

\textcolor{blue}{In addition to point forecasts, we generated probabilistic forecasts to capture the uncertainty surrounding future pharmaceutical consumption. Several approaches are available for generating probabilistic forecasts, including analytical prediction intervals, quantile regression, Bayesian modeling through Markov Chain Monte Carlo (MCMC) methods, bootstrapping, and conformal prediction} [@wang2023].

\textcolor{blue}{In this study, we employed a bootstrapping approach to construct predictive intervals. Bootstrapping was chosen primarily for its flexibility and model-agnostic nature, allowing it to be applied uniformly across the diverse range of forecasting methods implemented without requiring strong distributional assumptions. Moreover, pharmaceutical consumption data often exhibit irregular and volatile patterns, making non-parametric approaches like bootstrapping particularly suitable.}

\textcolor{blue}{Specifically, we assume that future forecast errors will be similar to past forecast errors. The forecast error at time $t$ is defined as: $e_t = y_t - \hat{y}_t$, where $y_t$ represents the observed consumption, and $\hat{y}_t$ denotes the corresponding forecast estimate. To simulate future consumption paths, we randomly sample errors with replacement from the historical error distribution and add them to the point forecast estimates. This process is repeated multiple times (1,000 iterations in our study) to generate a distribution of possible outcomes for each forecast horizon.}

\textcolor{blue}{Prediction intervals at the desired confidence level (e.g., 95\%) are then constructed by taking appropriate quantiles from the empirical distribution of the simulated forecasts} [@hyndman2021forecasting]. 

\textcolor{blue}{The bootstrapping method thus provides a robust and flexible framework to quantify forecast uncertainty across a heterogeneous set of pharmaceutical products without imposing restrictive parametric assumptions.}

## Performance evaluation

\textcolor{blue}{To evaluate the performance of our forecasting models, we split the data into a series of training and test sets and employed a time series cross-validation approach, following best practices for forecasting evaluation} [@hyndman2021forecasting]. \textcolor{blue}{Rather than using a fixed training and test split, we used a rolling-origin cross-validation framework, which allows for a more comprehensive assessment across different demand patterns and periods. In our setup, the initial training set consisted of all available historical data from December 2017 up to June 2021. The evaluation period covered the subsequent 12 months, reflecting the operational needs of the EPSS, which plans consumption over a one-year horizon. At each iteration, models were trained on an expanding training window and evaluated over a fixed 6-month forecast horizon, aligned with typical EPSS planning cycles. After each forecast generation, the training set was expanded by one additional month, and the process was repeated, allowing for rolling assessment across the final 12 months of data. This structure ensured that forecasts reflected realistic operational scenarios, where forecasts are continuously updated as new data becomes available. This cross-validation design allowed us to evaluate each model's ability to perform across multiple different forecast origins and a variety of demand conditions, providing a more reliable and generalizable understanding of model performance. Furthermore, all model development steps, including hyperparameter tuning for the LSTM models, were conducted exclusively using the training data available at each iteration. No test set information was used during model selection or tuning.}


The error metrics presented here consider a forecasting horizon denoted by  by $j$, which represents the number of time periods ahead we are predicting, with $j$ ranging from 1 to 6 months in our study. Point forecast accuracy is measured using the Mean Squared Scaled Error (MSSE) and the Mean Absolute Scaled Error (MASE). The Mean Absolute Scaled Error (MASE) [@HK06; @hyndman2021forecasting] is calculated as follows:

$$
  \text{MASE} = \text{mean}(|q_{j}|),
$$
where
$$
  q_{j} = \frac{ e_{j}}
 {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T |y_{t}-y_{t-m}|},
$$
and $e_{j}$ is the point forecast error for forecast horizon $j$, $m = 12$ (as we have monthly seasonal series), $y_t$ is the observation for period $t$, and $T$ is the sample size (the number of observations used for training the forecasting model). The denominator is the mean absolute error of the seasonal naive method in the fitting sample of $T$ observations and is used to scale the error. Smaller MASE values suggest more accurate forecasts. Note that the measure is scale-independent, thus allowing us to average the results across series.

Here, $e_{j}$ represents the point forecast error for forecast horizon $j$, with $m = 12$ (since we are dealing with monthly seasonal data). The term $y_t$ denotes the observation at time $t$, and $T$ is the sample size, or the number of observations used for training the forecasting model. The denominator in the MASE formula is the mean absolute error of the seasonal naive method over the training sample of $T$ observations, providing a basis for scaling the forecast error. Lower MASE values indicate more accurate forecasts. Notably, this measure is scale-independent, allowing us to average results across different series for broader performance comparison.

A related measure is MSSE [@hyndman2021forecasting;@makridakis2022m5], which uses squared errors rather than absolute errors:
$$
  \text{MSSE} = \text{mean}(q_{j}^2),
$$ {#eq-RMSSE}
where,
$$
  q^2_{j} = \frac{ e^2_{j}}
 {\displaystyle\frac{1}{T-m}\sum_{t=m+1}^T (y_{t}-y_{t-m})^2},
$$
Again, this is scale-independent, and smaller MSSE values suggest more accurate forecasts.


To measure the forecast distribution accuracy, we calculate the Continuous Rank Probability Score [@hyndman2021forecasting]. It rewards sharpness and penalizes miscalibration, so it measures overall performance of the forecast distribution. For probabilistic evaluation, 1,000 future paths were simulated per series, enabling robust estimation of forecast uncertainty.

$$
  \text{CRPS} = \text{mean}(p_j),
$$ {#eq-CRPS}
where
$$
  p_j = \int_{-\infty}^{\infty} \left(G_j(x) - F_j(x)\right)^2dx,
$$
where $G_j(x)$ is the forecasted probability distribution function for forecast horizon $j$, and $F_j(x)$ is the true probability distribution function for the same period.

Calibration refers to the statistical consistency between the distributional forecasts and the observations. It measures how well the predicted probabilities match the observations. On the other hand, sharpness refers to the concentration of the forecast distributions --- a sharp forecast distribution results in narrow prediction intervals, indicating high confidence in the forecast. A model is well-calibrated if the predicted probabilities match the distribution of the observations, and it is sharp if it is confident in its predictions. The CRPS rewards sharpness and calibration by assigning lower scores to forecasts with sharper distributions, and to forecasts that are well-calibrated. Thus, it is a metric that combines both sharpness and miscalibration into a single score, making it a useful tool for evaluating the performance of probabilistic forecasts.

CRPS can be considered an average of all possible quantiles [@hyndman2021forecasting, Section 5.9], and thus provides an evaluation of all possible prediction intervals or quantiles. A specific prediction interval could be evaluated using a Winkler score, if required. 



  
  
