# Results and discussion {#sec-results}

```{r}
#| include: false
#| label: restults
library(readr)
point_accuracy_h <- read_rds("../result/accuracy_h.rds") |> janitor::clean_names() |> select(item, h,model,mase,rmsse)
prob_accuracy_h <- read_rds("../result/accuracy_h.rds") |> janitor::clean_names() |> select(item, h,model,crps_skill,winkler_skill=skill,crps,winkler)

point_accuracy_id <- read_rds("../result/accuracy_id.rds")|> janitor::clean_names() |> select(item, id,model,mase,rmsse)
prob_accuracy_id <- read_rds("../result/accuracy_id.rds")|> janitor::clean_names() |> select(item, id,model,crps_skill,winkler_skill=skill,crps,winkler)

point_accuracy_horizon <- read_rds("../result/point_accuracy_horizon.rds") |> select(item, h=horizon,model,mase,rmsse)
prob_accuracy_horizon <- read_rds("../result/prob_accuracy_horizon.rds") |>  janitor::clean_names() |> select(item, h=horizon,model,crps_skill=crps_skill_score,winkler_skill=winkler_skill_score,crps,winkler=winkler_score)

point_accuracy_origin <- read_rds("../result/point_accuracy_origin.rds") |> janitor::clean_names() |> select(item, id=origin,model,mase,rmsse)
prob_accuracy_origin <- read_rds("../result/prob_accuracy_origin.rds") |> janitor::clean_names() |> select(item, id=origin,model,crps_skill=crps_skill_score,winkler_skill=winkler_skill_score,crps,winkler=winkler_score)

point_accuracy_h_all <- point_accuracy_h |> bind_rows(point_accuracy_horizon |> mutate(h= as.integer(h)))
prob_accuracy_h_all <- prob_accuracy_h |> bind_rows(prob_accuracy_horizon |> mutate(h= as.integer(h)))

point_accuracy_origin_all <- point_accuracy_id |> bind_rows(point_accuracy_origin |> mutate(id= as.integer(id)))
prob_accuracy_origin_all <- prob_accuracy_id |> bind_rows(prob_accuracy_origin |> mutate(id= as.integer(id)))

```


In this section, we compare the forecasting performance of various approaches, examining models that incorporate expert-identified business context predictors versus those that rely solely on historical consumption data. Point forecast performance is reported using MASE and MSSE, while probabilistic forecast accuracy is reported using CRPS. 

The forecasting performance is reported in @fig-point, in which the average forecast accuracy over forecast horizon and across all products is calculated for each origin. we also report the ditribution of accurcy metrics  across all rollog origins, average across forecast horizon and all products. this shows how mdoels varies in roviding accuracy across different origins. further rserach would be required to understand how error analysis across forecast hrizon and across differne origins could be used as afiagnos!
y-axis shows the models sorted based on ther values of mase and rmsse, when the one i the bottom has lowest error. this modesis TimeGpt, which is the foundational time sei models. 


@fig-point also indicate that predictors collected through interacting with experts with domaine knoeldge improves point forecast accuracy for all models, highlighting the essential needs to systematically colelct such information alognside the tarsactional data about consuption. 

We observed that the LSTM model had the highest error compared to all other models. While LSTMs are powerful for capturing complex, non-linear temporal patterns, they may underperform in certain scenarios, especially when compared to simpler time series forecasting models. This underperformance can be attributed to overfitting, as LSTMs have a large number of parameters and require substantial amounts of data to generalize effectively. In contrast, simpler models like ARIMA with exogenous variables often handle straightforward trends or seasonality more effectively and may outperform LSTMs when long-term dependencies or non-linearity in the data are not significant.


```{r}
#| label: fig-point
#| fig-width: 7
#| fig-height: 5
#| fig-cap: "Distribution of point forecast accuracy across different origins, averaged across the forecat horizon and all products. The total number of months used to calculate the accuracy in the test set is 12 months for each product. MASE and MSSE are relative to the corresponding values for the training set."
#| fig-pos: "H"

p_mase <- point_accuracy_origin_all |> ggplot(aes(x= mase, y =  fct_reorder(model, mase)))+
  geom_boxplot()+
  labs(y = "Models")+
  ggthemes::theme_few()

p_rmsse <- point_accuracy_origin_all |> ggplot(aes(x= rmsse, y =  fct_reorder(model, mase)))+
  geom_boxplot()+
  labs(y = "Models")+
  ggthemes::theme_few()

point_patch <- p_mase/p_rmsse

point_patch+ggthemes::theme_few()

```


```{r}
#| label: fig-prob
#| fig-width: 9
#| fig-height: 3
#| fig-cap: "Distribution of probabilistic forecast accuracy across different origins, averaged across the forecat horizon and all products. The total number of months used to calculate the accuracy in the test set is 12 months for each product."
#| fig-pos: "H"

prob_accuracy_origin_all |> ggplot(aes(x= crps, y =  fct_reorder(model, crps)))+
  geom_boxplot()+
  labs(y = "Models")+
  ggthemes::theme_few()

```


```{r}
#| label: fig-horizon
#| fig-width: 11
#| fig-height: 5
#| fig-cap: "Average accuracy by month for 6 month. The total number of months used to calculate the accuracy in the test set is 12 for each product."
#| fig-pos: "H"

p1h <- point_accuracy_h_all |> group_by(model,h) |> summarise(mase=mean(mase) , .groups = "drop")|> filter(model != "lstm", model != "lstm_reg") |>  ggplot(aes(x = h, y = mase, colour =model))+
  geom_point()+
  geom_line()+
  ggthemes::theme_few()+
  ggthemes::scale_color_colorblind()+
  labs(x= " Forecast horizon")+
  theme(legend.position="none")

p2h <- point_accuracy_h_all |> group_by(model,h) |> summarise(rmsse=mean(rmsse),.groups = "drop") |> filter(model != "lstm", model != "lstm_reg") |> 
  ggplot(aes(x = h, y = rmsse, colour =model))+
  geom_point()+
  geom_line()+
  ggthemes::theme_few()+
  ggthemes::scale_color_colorblind()+
  labs(x= " Forecast horizon")+
  theme(legend.position="bottom")

p3h <- prob_accuracy_h_all |> group_by(model,h) |> summarise(crps=mean(crps),.groups = "drop") |> filter(model != "lstm", model != "lstm_reg") |> 
  ggplot(aes(x = h, y = crps, colour =model))+
  geom_point()+
  geom_line()+
  ggthemes::theme_few()+
  ggthemes::scale_color_colorblind()+
  labs(x= " Forecast horizon")+
  theme(legend.position="none") 

prob_patch <- (p1h|p2h|p3h)
prob_patch
```


@fig-prob illustrates the forecast distribution accuracy measured by the Continuous Ranked Probability Score (CRPS), which evaluates both forecasting calibration and interval sharpness. A smaller CRPS value indicates better overall performance. We observed that incorporating domain knowledge improved forecast accuracy for most models, enhancing not only point forecasts but also probabilistic forecasts. Notably, TimeGpt achieved the highest probabilistic forecast accuracy, while LSTM models had the lowest. This aligns with the findings related to point forecast accuracy, reinforcing the earlier explanations for these results.

In addition to reporting the forecast accuracy presented across different rolling origins, we also report the point and probabilistic forecast accuracy measures for each forecast horizon in @fig-horizon. this is the accuracy reorted as the average across rolling origins and all products fro each given horizon. For both the point forecast and distributional accuracy  we can see that models incoporating information collected by domain experts improves compared to counterparts that that uses only the historical comsuptions. 

Overall, our results indicate that forecast produces using models with infromation colelcted via the domain expert engagement provides reliable forecasts and improves upon the models relying solely on historcial consuption. 


Our analysis highlights the value of using foundational time series forecasting models like TimeGpt, particularly in developing countries and the global health and humanitarian sectors. In these contexts, the lack of advanced analytical skills and systematic data collection can hinder effective forecasting and decision-making. 

The findings also emphasize the importance of incorporating relevant domain knowledge into forecasting models. In pharmaceutical supply logistics administration systems, data often consists solely of transactional records on consumption and distribution. Including exogenous variables such as administrative procedures, seasonal patterns, or conflicts, or any other relevant factor that could be identified by those with domain knowledge proved essential for reducing forecast errors. This approach improved both point and probabilistic forecast accuracy, enabling a more confident assessment of uncertainty. Therefore, the systematic collection of information about significant events and their impact on consumption is vital. Recording details of events such as policy changes, administration procedures, conflicts, and incorporating this information into forecasting models creates a comprehensive understanding of consumption. This practice enhances modeling reliability and allows institutions in developing countries and humanitarian organizations to better forecast demand, allocate resources effectively, and respond proactively. Establishing robust data collection systems is thus a critical step for strengthening forecasting capabilities and operational resilience.

## An illustration of probabilistic forecast for Pharmacuitical product consumption

In this section, we present an illustrative example of a probabilistic forecast for future consumption of _Sodium Chloride (Normal Saline)_ product. Due to the complexity of including such visualizations for all products, only one example is shown here. However, it is feasible to generate these plots for all products if needed.

In practice, point forecasts are commonly used despite their limitations, but they do not account for the inherent uncertainty associated with forecasts. The future is inherently uncertain, and effective planning requires considering alternative scenarios. Probabilistic forecasts offer a comprehensive approach by assigning likelihoods to a range of possible outcomes, recognizing that different consumption levels may occur with varying probabilities. The primary purpose of probabilistic forecasting, as illustrated in @fig-forecast-density-hstep, is to quantify and communicate uncertainty. This figure displays the forecast distribution of consumption over a 6-month horizon using a density plot. For each month within the forecast period, a separate distribution is generated. The plot also includes the point forecast alongside 80% and 90% prediction intervals to illustrate potential variability.

It is important to note that while point forecasts and prediction intervals can be derived from probabilistic forecasts, the reverse is not true. A single-point forecast cannot inherently provide the probabilistic context needed to capture the range of possible outcomes. Although prediction intervals can indicate a range of potential values, they do not convey the detailed probabilities of low or high consumption. This distinction highlights the value of probabilistic forecasting in supporting informed decision-making by offering a clearer view of future uncertainties.


```{r}
#| label: fig-forecast-density-hstep
#| fig-width: 9
#| fig-height: 4
#| fig-cap: "A graphical illustration of the forecast distribution of a pharmacutical product (i.e. total incidence attended) for the SB health board for a horizon of six month. For each month, we display the point forecast (black point), the histogram, and 80% (thick line) and 90% (thin line) prediction intervals. It also shows a portion of a historical time series as well as its fitted values."
#| fig-pos: "H"

amoxicillin <- med_qty |> filter(item == "Sodium Chloride (Normal Saline)") |> select(month,quantity) |> 
  as_tsibble(index = month)


fit <- amoxicillin |> filter_index(. ~ "2022 Jan") |>
  model(ets = ARIMA(quantity))

fcst <- fit |> forecast(h = 6)
fitted_ets <- fit |> augment()

ggplot(data = fcst, mapping = aes(x = month, ydist = quantity))+
  ggdist::stat_halfeye(alpha = .4)+
  geom_line(aes(y=.mean, colour ="Point Forecast"))+
  geom_line(aes(y = .fitted, colour ="Fitted"), data = filter_index(fitted_ets, "2021 Jan" ~ .))+
  geom_point(aes(y = .fitted, colour ="Fitted"), data = filter_index(fitted_ets, "2021 Jan" ~ .))+
  geom_line(aes(y = quantity, colour ="Actual"),data = filter_index(amoxicillin, "2021 Jan" ~ .))+
  geom_point(aes(y = quantity, colour ="Actual"),data = filter_index(amoxicillin, "2021 Jan" ~ .))+
  scale_color_manual(name=NULL,
                     breaks=c('Fitted', 'Actual',"Point Forecast"),
                     values=c('Fitted'='#E69F00', 'Actual'='#0072B2',"Point Forecast"="#000000"))+
  ggthemes::theme_few()
```



